{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data (replace 'your_data.csv' with your actual file)\n",
    "data = pd.read_csv(r\"Datasets\\food-contamination-data-cleaned-2.csv\")\n",
    "\n",
    "# Define X and Y\n",
    "X = data.drop('ResultValue', axis=1) # All columns except ResultValue\n",
    "y = data['ResultValue'] # The ResultValue column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply log transformation to the target variable (y_train and y_test)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Identify categorical and numerical columns (assuming you've done this)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'regressor__max_depth': None, 'regressor__max_features': None, 'regressor__min_samples_leaf': 10, 'regressor__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessor (assuming you've done this)\n",
    "numerical_transformer = 'passthrough'\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n",
    "                                               ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Create the Decision Tree Regressor pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DecisionTreeRegressor(random_state=42))])\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 5, 10, 15, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10, 20],\n",
    "    'regressor__min_samples_leaf': [1, 3, 5, 10],\n",
    "    'regressor__max_features': ['sqrt', 'log2', None]  # None means consider all features\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data (using the log-transformed target)\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_decision_tree_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_log_tuned = best_decision_tree_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions back to the original scale\n",
    "y_pred_original_scale_tuned = np.expm1(y_pred_log_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with Tuned Decision Tree (Log Transformed Target):\n",
      "Decision Tree MSE (Original Scale): 691.1721707067279\n",
      "Decision Tree R-squared (Original Scale): 0.6134339947857661\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the original scale predictions\n",
    "mse_tuned = mean_squared_error(y_test, y_pred_original_scale_tuned)\n",
    "r2_tuned = r2_score(y_test, y_pred_original_scale_tuned)\n",
    "\n",
    "print(\"\\nResults with Tuned Decision Tree (Log Transformed Target):\")\n",
    "print(f'Decision Tree MSE (Original Scale): {mse_tuned}')\n",
    "print(f'Decision Tree R-squared (Original Scale): {r2_tuned}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'named_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m model_to_be_tested = y_pred_original_scale_tuned\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Get the prediction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m prediction = \u001b[43mpredict_contamination\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_to_be_tested\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumerical_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicted Contamination Level: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m micrograms/kg\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mpredict_contamination\u001b[39m\u001b[34m(user_input_dict, best_model, numerical_cols, categorical_cols)\u001b[39m\n\u001b[32m     26\u001b[39m         user_input_df[col] = \u001b[33m'\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Or some other appropriate default\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Preprocess the user input using the same preprocessor in the pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m preprocessed_input = \u001b[43mbest_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnamed_steps\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m'\u001b[39m].transform(user_input_df)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Make prediction (which will be on the log scale)\u001b[39;00m\n\u001b[32m     32\u001b[39m predicted_log = best_model.named_steps[\u001b[33m'\u001b[39m\u001b[33mregressor\u001b[39m\u001b[33m'\u001b[39m].predict(preprocessed_input)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'named_steps'"
     ]
    }
   ],
   "source": [
    "#User testing block\n",
    "\n",
    "def predict_contamination(user_input_dict, best_model, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Predicts the contamination level based on user input.\n",
    "\n",
    "    Args:\n",
    "        user_input_dict (dict): A dictionary containing the user's input\n",
    "                                 for the features (keys should match column names).\n",
    "        best_model (Pipeline): The trained best Decision Tree Regressor model.\n",
    "        numerical_cols (list): List of numerical column names.\n",
    "        categorical_cols (list): List of categorical column names.\n",
    "\n",
    "    Returns:\n",
    "        float: The predicted contamination level (original scale).\n",
    "    \"\"\"\n",
    "    user_input_df = pd.DataFrame([user_input_dict])\n",
    "\n",
    "    # Ensure all necessary columns are present (handle missing if needed)\n",
    "    for col in numerical_cols:\n",
    "        if col not in user_input_df.columns:\n",
    "            user_input_df[col] = 0  # Or some other appropriate default\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if col not in user_input_df.columns:\n",
    "            user_input_df[col] = 'unknown'  # Or some other appropriate default\n",
    "\n",
    "    # Preprocess the user input using the same preprocessor in the pipeline\n",
    "    preprocessed_input = best_model.named_steps['preprocessor'].transform(user_input_df)\n",
    "\n",
    "    # Make prediction (which will be on the log scale)\n",
    "    predicted_log = best_model.named_steps['regressor'].predict(preprocessed_input)\n",
    "\n",
    "    # Inverse transform the prediction to the original scale\n",
    "    predicted_original_scale = np.expm1(predicted_log)[0]  # [0] to get the single prediction\n",
    "\n",
    "    return predicted_original_scale\n",
    "\n",
    "# Example user input\n",
    "user_input = {\n",
    "    'FoodID': 123,\n",
    "    'CountryName': 'USA',\n",
    "    'FoodGroupName': 'Fruits',\n",
    "    'GEMSFoodName': 'Apples',\n",
    "    'ContaminantID': 45,\n",
    "    'ContaminantName': 'Pesticide X',\n",
    "    'Year': 2024,\n",
    "    'ContaminationIndividualID': 789  # Include if it was part of your features\n",
    "}\n",
    "\n",
    "#update before every test\n",
    "model_to_be_tested = y_pred_original_scale_tuned\n",
    "\n",
    "# Get the prediction\n",
    "prediction = predict_contamination(user_input, model_to_be_tested, numerical_cols, categorical_cols)\n",
    "\n",
    "print(f\"Predicted Contamination Level: {prediction:.2f} micrograms/kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a specific sample you want to classify (e.g., the first one in your test set)\n",
    "sample_index = 7\n",
    "sample_features = X_test.iloc[[sample_index]]  # Get the features for the sample\n",
    "predicted_log = best_decision_tree_model.predict(sample_features)\n",
    "predicted_value = np.expm1(predicted_log)[0] # Inverse transform if needed\n",
    "\n",
    "# Get the contaminant name for this sample (assuming your test set still has this info)\n",
    "contaminant = X_test.iloc[sample_index]['ContaminantName'] # Adjust if needed\n",
    "\n",
    "thresholds = {\n",
    "    \"Ethyl carbamate\": 400,\n",
    "    \"Cesium 134\": 1000,\n",
    "    \"Cesium 137\": 1000,\n",
    "    \"Iodine 131\": 100,\n",
    "    \"Cesium total\": 1000,\n",
    "    \"Dioxins (WHO TEFs)\": 2,\n",
    "    \"Dioxin like PCBs (WHO TEFs)\": 3,\n",
    "    \"Lead\": 100,\n",
    "    \"Cadmium\": 100,\n",
    "    \"Aflatoxin (total)\": 15,\n",
    "    \"Aflatoxin B1\": 5,\n",
    "    \"Aflatoxin B2\": 2,\n",
    "    \"Aflatoxin G1\": 2,\n",
    "    \"Aflatoxin G2\": 2,\n",
    "    \"Aflatoxin M1\": 0.5,\n",
    "    \"Tin\": 250,\n",
    "    \"Copper\": 10000,\n",
    "    \"Mercury\": 50,\n",
    "    \"Methyl mercury\": 100,\n",
    "    \"Fumonisin B1\": 1000,\n",
    "    \"Fumonisin B2\": 1000,\n",
    "    \"Fumonisin B3\": 1000,\n",
    "    \"Patulin\": 50,\n",
    "    \"Nitrite\": 20,\n",
    "    \"Arsenic (total)\": 200,\n",
    "    \"Arsenic (inorganic)\": 100,\n",
    "    \"Deoxynivalenol\": 1000,\n",
    "    \"3-Chloro-1,2-propanediol\": 20,\n",
    "    \"Ochratoxin A\": 5,\n",
    "    \"Zearalenone\": 100,\n",
    "    \"Hexachlorobenzene\": 10,\n",
    "    \"Hexachlorocyclohexanes (HCH)\": 50,\n",
    "    \"Pyrrolizidine alkaloids\":100\n",
    "}\n",
    "\n",
    "safety_threshold = thresholds.get(contaminant, float('inf'))\n",
    "safety_label = \"Safe\" if predicted_value <= safety_threshold else \"Unsafe\"\n",
    "\n",
    "print(\"Sample is classified as:\", safety_label)\n",
    "print(f\"Predicted value for {contaminant}: {predicted_value:.2f}\")\n",
    "print(f\"Safety threshold for {contaminant}: {safety_threshold}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
