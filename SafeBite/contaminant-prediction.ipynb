{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data (replace 'your_data.csv' with your actual file)\n",
    "data = pd.read_csv(r\"Datasets\\food-contamination-data-cleaned-2.csv\")\n",
    "\n",
    "# Define X and Y\n",
    "X = data.drop('ResultValue', axis=1) # All columns except ResultValue\n",
    "y = data['ResultValue'] # The ResultValue column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns (assuming you've done this before)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Create preprocessor (assuming you've done this before)\n",
    "numerical_transformer = 'passthrough'\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n",
    "                                               ('cat', categorical_transformer, categorical_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformers for categorical and numerical columns\n",
    "numerical_transformer = 'passthrough' # No transformation needed for numerical\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessing and the linear regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1704.746408723103\n",
      "R-squared: 0.04655158721223818\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)   \n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the r2 value is very low, the data is not related in a linear manner. it must be regularised. L1 / Lasso Regularisation is being used below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23035910.87468704, tolerance: 6983.133609285355\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22958295.30327101, tolerance: 6951.078707136703\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22855603.947489653, tolerance: 6909.2075906941345\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22871801.094512634, tolerance: 6910.561009616364\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23010473.22436601, tolerance: 6967.123798001029\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23578964.97583322, tolerance: 6983.133609285355\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23499894.365853194, tolerance: 6951.078707136703\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23207131.8576776, tolerance: 6909.2075906941345\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23236019.829114765, tolerance: 6910.561009616364\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n",
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23255620.02861666, tolerance: 6967.123798001029\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lasso alpha: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ananya\\Documents\\GitHub\\SafeBite\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28728446.119015217, tolerance: 8680.279789380971\n",
      "  model = cd_fast.sparse_enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Create Lasso model in a pipeline\n",
    "lasso_model = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                              ('regressor', Lasso())])\n",
    "\n",
    "# Define the parameter grid for alpha tuning\n",
    "param_grid = {'regressor__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Create GridSearchCV object for cross-validation\n",
    "grid_search_lasso = GridSearchCV(lasso_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print the best alpha value\n",
    "print(f'Best Lasso alpha: {grid_search_lasso.best_params_[\"regressor__alpha\"]}')\n",
    "\n",
    "# Get the best Lasso model\n",
    "best_lasso_model = grid_search_lasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso MSE: 1188.1131293703013\n",
      "Lasso R-squared: 0.3354996546032245\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best Lasso model on the test set\n",
    "y_pred_lasso = best_lasso_model.predict(X_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f'Lasso MSE: {mse_lasso}')\n",
    "print(f'Lasso R-squared: {r2_lasso}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the MSE value has lowered, the deviation is still much to large.\n",
    "R2 values indicate that the model is not able to explain 66% of the variance in contamination\n",
    "\n",
    "Next approach:\n",
    "1. transformations\n",
    "2. decision tree regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For transformations:\n",
    "1. Visualise using histogram\n",
    "2. try log transformation \n",
    "3. if doesnt work, try box-cox or yeo-johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['ResultValue'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is heavily skewed to the right, we'll first perform log transformation and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply log transformation to the target variable (y)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "#run the preprocessing cell after this if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree Regressor model in a pipeline\n",
    "decision_tree_log_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                         ('regressor', DecisionTreeRegressor(random_state=42))])\n",
    "\n",
    "# Train the model on the log-transformed target variable\n",
    "decision_tree_log_model.fit(X_train, y_train_log)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = decision_tree_log_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions back to the original scale\n",
    "y_pred_original_scale = np.expm1(y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Log Transformation:\n",
      "Decision Tree MSE (Original Scale): 902.5868017951003\n",
      "Decision Tree R-squared (Original Scale): 0.495191807314433\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the original scale predictions\n",
    "mse_log = mean_squared_error(y_test, y_pred_original_scale)\n",
    "r2_log = r2_score(y_test, y_pred_original_scale)\n",
    "\n",
    "print(\"Results with Log Transformation:\")\n",
    "print(f'Decision Tree MSE (Original Scale): {mse_log}')\n",
    "print(f'Decision Tree R-squared (Original Scale): {r2_log}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results without Log Transformation:\n",
      "Decision Tree MSE (Original Scale): 904.4470350562799\n",
      "Decision Tree R-squared (Original Scale): 0.49415139658752905\n"
     ]
    }
   ],
   "source": [
    "# You can also train and evaluate a model without log transformation for comparison\n",
    "decision_tree_original_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                              ('regressor', DecisionTreeRegressor(random_state=42))])\n",
    "decision_tree_original_model.fit(X_train, y_train)\n",
    "y_pred_original = decision_tree_original_model.predict(X_test)\n",
    "mse_original = mean_squared_error(y_test, y_pred_original)\n",
    "r2_original = r2_score(y_test, y_pred_original)\n",
    "\n",
    "print(\"\\nResults without Log Transformation:\")\n",
    "print(f'Decision Tree MSE (Original Scale): {mse_original}')\n",
    "print(f'Decision Tree R-squared (Original Scale): {r2_original}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Contamination Level: 1.00 micrograms/kg\n"
     ]
    }
   ],
   "source": [
    "#User testing block\n",
    "\n",
    "def predict_contamination(user_input_dict, best_model, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Predicts the contamination level based on user input.\n",
    "\n",
    "    Args:\n",
    "        user_input_dict (dict): A dictionary containing the user's input\n",
    "                                 for the features (keys should match column names).\n",
    "        best_model (Pipeline): The trained best Decision Tree Regressor model.\n",
    "        numerical_cols (list): List of numerical column names.\n",
    "        categorical_cols (list): List of categorical column names.\n",
    "\n",
    "    Returns:\n",
    "        float: The predicted contamination level (original scale).\n",
    "    \"\"\"\n",
    "    user_input_df = pd.DataFrame([user_input_dict])\n",
    "\n",
    "    # Ensure all necessary columns are present (handle missing if needed)\n",
    "    for col in numerical_cols:\n",
    "        if col not in user_input_df.columns:\n",
    "            user_input_df[col] = 0  # Or some other appropriate default\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if col not in user_input_df.columns:\n",
    "            user_input_df[col] = 'unknown'  # Or some other appropriate default\n",
    "\n",
    "    # Preprocess the user input using the same preprocessor in the pipeline\n",
    "    preprocessed_input = best_model.named_steps['preprocessor'].transform(user_input_df)\n",
    "\n",
    "    # Make prediction (which will be on the log scale)\n",
    "    predicted_log = best_model.named_steps['regressor'].predict(preprocessed_input)\n",
    "\n",
    "    # Inverse transform the prediction to the original scale\n",
    "    predicted_original_scale = np.expm1(predicted_log)[0]  # [0] to get the single prediction\n",
    "\n",
    "    return predicted_original_scale\n",
    "\n",
    "# Example user input\n",
    "user_input = {\n",
    "    'FoodID': 123,\n",
    "    'CountryName': 'USA',\n",
    "    'FoodGroupName': 'Fruits',\n",
    "    'GEMSFoodName': 'Apples',\n",
    "    'ContaminantID': 45,\n",
    "    'ContaminantName': 'Pesticide X',\n",
    "    'Year': 2024,\n",
    "    'ContaminationIndividualID': 789  # Include if it was part of your features\n",
    "}\n",
    "\n",
    "#update before every test\n",
    "model_to_be_tested = decision_tree_log_model\n",
    "\n",
    "# Get the prediction\n",
    "prediction = predict_contamination(user_input, model_to_be_tested, numerical_cols, categorical_cols)\n",
    "\n",
    "print(f\"Predicted Contamination Level: {prediction:.2f} micrograms/kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'regressor__max_depth': None, 'regressor__max_features': None, 'regressor__min_samples_leaf': 10, 'regressor__min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply log transformation to the target variable (y_train and y_test)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Identify categorical and numerical columns (assuming you've done this)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Create preprocessor (assuming you've done this)\n",
    "numerical_transformer = 'passthrough'\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n",
    "                                               ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Create the Decision Tree Regressor pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', DecisionTreeRegressor(random_state=42))])\n",
    "\n",
    "# Define the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'regressor__max_depth': [None, 5, 10, 15, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10, 20],\n",
    "    'regressor__min_samples_leaf': [1, 3, 5, 10],\n",
    "    'regressor__max_features': ['sqrt', 'log2', None]  # None means consider all features\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data (using the log-transformed target)\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_decision_tree_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "y_pred_log_tuned = best_decision_tree_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions back to the original scale\n",
    "y_pred_original_scale_tuned = np.expm1(y_pred_log_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with Tuned Decision Tree (Log Transformed Target):\n",
      "Decision Tree MSE (Original Scale): 691.1721707067279\n",
      "Decision Tree R-squared (Original Scale): 0.6134339947857661\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the original scale predictions\n",
    "mse_tuned = mean_squared_error(y_test, y_pred_original_scale_tuned)\n",
    "r2_tuned = r2_score(y_test, y_pred_original_scale_tuned)\n",
    "\n",
    "print(\"\\nResults with Tuned Decision Tree (Log Transformed Target):\")\n",
    "print(f'Decision Tree MSE (Original Scale): {mse_tuned}')\n",
    "print(f'Decision Tree R-squared (Original Scale): {r2_tuned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is performing better, to further optimise it, we evaluate feature importance. It tells us which feature influences the result the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "num__ContaminationIndividualID: 0.4864\n",
      "num__ContaminantID: 0.3533\n",
      "cat__CountryName_China: 0.0611\n",
      "cat__CountryName_Singapore: 0.0276\n",
      "num__Year: 0.0162\n",
      "cat__ContaminantName_Lead: 0.0064\n",
      "num__FoodID: 0.0061\n",
      "cat__GEMSFoodName_FISHES: 0.0051\n",
      "cat__CountryName_HONG KONG SAR: 0.0051\n",
      "cat__CountryName_Republic of Korea: 0.0044\n",
      "cat__ContaminantName_Iodine 131: 0.0040\n",
      "cat__GEMSFoodName_Cattle milk: 0.0020\n",
      "cat__FoodGroupName_Fruit and fruit products: 0.0018\n",
      "cat__GEMSFoodName_Rays: 0.0017\n",
      "cat__ContaminantName_Other: 0.0017\n",
      "cat__GEMSFoodName_Flounders: 0.0016\n",
      "cat__GEMSFoodName_MEAT FROM MAMMALS OTHER THAN MARINE MAMMALS: 0.0012\n",
      "cat__FoodGroupName_Vegetables and vegetable products (including fungi): 0.0012\n",
      "cat__GEMSFoodName_Pollack: 0.0012\n",
      "cat__CountryName_Thailand: 0.0010\n",
      "cat__FoodGroupName_Meat and meat products (including edible offal): 0.0009\n",
      "cat__GEMSFoodName_Starchy roots and tubers NES: 0.0008\n",
      "cat__GEMSFoodName_Mushrooms: 0.0008\n",
      "cat__ContaminantName_Cadmium: 0.0006\n",
      "cat__FoodGroupName_Milk and dairy products: 0.0006\n",
      "cat__GEMSFoodName_Spinach (bunch): 0.0006\n",
      "cat__GEMSFoodName_Pig meat: 0.0005\n",
      "cat__GEMSFoodName_LEAFY VEGETABLES: 0.0005\n",
      "cat__FoodGroupName_Starchy roots and tubers: 0.0005\n",
      "cat__GEMSFoodName_Bamboo shoots: 0.0004\n",
      "cat__GEMSFoodName_Vegetables and vegetable products NES: 0.0004\n",
      "cat__CountryName_Japan: 0.0004\n",
      "cat__GEMSFoodName_Cattle meat: 0.0004\n",
      "cat__FoodGroupName_Eggs and egg products: 0.0004\n",
      "cat__GEMSFoodName_Garlic: 0.0003\n",
      "cat__GEMSFoodName_CITRUS FRUITS: 0.0003\n",
      "cat__FoodGroupName_Fish and other seafood (including amphibians, reptiles, snails and insects): 0.0003\n",
      "cat__GEMSFoodName_Clams: 0.0003\n",
      "cat__GEMSFoodName_Peppers, sweet (incl. pim(i)ento): 0.0002\n",
      "cat__GEMSFoodName_Shrimps and prawns: 0.0002\n",
      "cat__GEMSFoodName_Grapes: 0.0002\n",
      "cat__GEMSFoodName_MILKS: 0.0001\n",
      "cat__GEMSFoodName_Spring onion: 0.0001\n",
      "cat__GEMSFoodName_Pig liver: 0.0001\n",
      "cat__GEMSFoodName_Taro: 0.0001\n",
      "cat__GEMSFoodName_Pear: 0.0001\n",
      "cat__GEMSFoodName_Fruit and fruit products NES: 0.0001\n",
      "cat__GEMSFoodName_Apple: 0.0001\n",
      "cat__GEMSFoodName_Apricot: 0.0001\n",
      "cat__GEMSFoodName_Kiwi fruit: 0.0001\n",
      "cat__GEMSFoodName_FRESH WATER FISHES: 0.0001\n",
      "cat__GEMSFoodName_Leek: 0.0001\n",
      "cat__GEMSFoodName_Meat and meat products NES: 0.0001\n",
      "cat__GEMSFoodName_Legumes and pulses NES: 0.0001\n",
      "cat__GEMSFoodName_Mackerel: 0.0001\n",
      "cat__GEMSFoodName_Fig: 0.0000\n",
      "cat__GEMSFoodName_MARINE FISHES: 0.0000\n",
      "cat__GEMSFoodName_Trout: 0.0000\n",
      "cat__GEMSFoodName_CRUSTACEANS: 0.0000\n",
      "cat__GEMSFoodName_Pig kidney: 0.0000\n",
      "cat__FoodGroupName_Legumes and pulses: 0.0000\n",
      "cat__GEMSFoodName_Soya bean (dry): 0.0000\n",
      "cat__GEMSFoodName_Mandarin: 0.0000\n",
      "cat__GEMSFoodName_MARINE MAMMALS: 0.0000\n",
      "cat__GEMSFoodName_Egg plant: 0.0000\n",
      "cat__GEMSFoodName_Carrot: 0.0000\n",
      "cat__GEMSFoodName_Peach: 0.0000\n",
      "cat__GEMSFoodName_Celery (whole): 0.0000\n",
      "cat__GEMSFoodName_Lettuce, leaf: 0.0000\n",
      "cat__GEMSFoodName_Salmon, Pacific: 0.0000\n",
      "cat__GEMSFoodName_Lentils: 0.0000\n",
      "cat__GEMSFoodName_Herring: 0.0000\n",
      "cat__GEMSFoodName_BULB VEGETABLES: 0.0000\n",
      "cat__GEMSFoodName_Potato: 0.0000\n",
      "cat__GEMSFoodName_Oysters (including cupped oysters): 0.0000\n",
      "cat__GEMSFoodName_Sweet potato: 0.0000\n",
      "cat__GEMSFoodName_Peppers, chili: 0.0000\n",
      "cat__GEMSFoodName_Crabs: 0.0000\n",
      "cat__GEMSFoodName_Mussels: 0.0000\n",
      "cat__GEMSFoodName_Pumpkins: 0.0000\n",
      "cat__GEMSFoodName_Octopuses: 0.0000\n",
      "cat__GEMSFoodName_Chicken eggs: 0.0000\n",
      "cat__GEMSFoodName_Yams: 0.0000\n",
      "cat__GEMSFoodName_Tomato: 0.0000\n",
      "cat__GEMSFoodName_Chicken meat: 0.0000\n",
      "cat__GEMSFoodName_Asparagus: 0.0000\n",
      "cat__CountryName_India: 0.0000\n",
      "cat__CountryName_Indonesia: 0.0000\n",
      "cat__GEMSFoodName_ASSORTED (SUB)TROPICAL FRUITS: 0.0000\n",
      "cat__GEMSFoodName_Artichoke globe: 0.0000\n",
      "cat__GEMSFoodName_BERRIES AND OTHER SMALL FRUITS: 0.0000\n",
      "cat__GEMSFoodName_BUTTER AND OTHER ANIMAL FAT EMULSION: 0.0000\n",
      "cat__GEMSFoodName_Banana: 0.0000\n",
      "cat__GEMSFoodName_Barramundi: 0.0000\n",
      "cat__GEMSFoodName_Beans (dry): 0.0000\n",
      "cat__GEMSFoodName_Beans, shelled (immature seeds): 0.0000\n",
      "cat__GEMSFoodName_Beetroot: 0.0000\n",
      "cat__GEMSFoodName_Blueberries: 0.0000\n",
      "cat__GEMSFoodName_Bottle gourd: 0.0000\n",
      "cat__GEMSFoodName_Brassica leafy vegetables: 0.0000\n",
      "cat__GEMSFoodName_Bream: 0.0000\n",
      "cat__GEMSFoodName_Broad bean, shelled (immature seeds): 0.0000\n",
      "cat__GEMSFoodName_Broccoli: 0.0000\n",
      "cat__GEMSFoodName_Broccoli, Chinese: 0.0000\n",
      "cat__GEMSFoodName_CHEESE AND ANALOGUES: 0.0000\n",
      "cat__GEMSFoodName_Cabbage, head: 0.0000\n",
      "cat__GEMSFoodName_Carambola (= star fruit): 0.0000\n",
      "cat__GEMSFoodName_Carps: 0.0000\n",
      "cat__GEMSFoodName_Cauliflower (head): 0.0000\n",
      "cat__GEMSFoodName_Cherries: 0.0000\n",
      "cat__GEMSFoodName_Chicory leaves (head): 0.0000\n",
      "cat__GEMSFoodName_Chinese cabbage, type pak-choi: 0.0000\n",
      "cat__GEMSFoodName_Chinese cabbage, type pe-tsai: 0.0000\n",
      "cat__GEMSFoodName_Cod: 0.0000\n",
      "cat__GEMSFoodName_Corn salad: 0.0000\n",
      "cat__GEMSFoodName_Cos lettuce: 0.0000\n",
      "cat__GEMSFoodName_Cress, garden: 0.0000\n",
      "cat__GEMSFoodName_Cucumber: 0.0000\n",
      "cat__GEMSFoodName_Custard apple: 0.0000\n",
      "cat__GEMSFoodName_DIADROMOUS FISHES: 0.0000\n",
      "cat__GEMSFoodName_DRIED FRUITS: 0.0000\n",
      "cat__GEMSFoodName_Dandelion leaves: 0.0000\n",
      "cat__GEMSFoodName_Date: 0.0000\n",
      "cat__GEMSFoodName_Deer meat: 0.0000\n",
      "cat__GEMSFoodName_Dried fish: 0.0000\n",
      "cat__GEMSFoodName_Duck eggs: 0.0000\n",
      "cat__GEMSFoodName_Duck meat: 0.0000\n",
      "cat__GEMSFoodName_Durian: 0.0000\n",
      "cat__GEMSFoodName_EDIBLE OFFALS (MAMMALIANS): 0.0000\n",
      "cat__GEMSFoodName_Eels: 0.0000\n",
      "cat__GEMSFoodName_Eggs and egg products NES: 0.0000\n",
      "cat__GEMSFoodName_FERMENTED MILK PRODUCTS: 0.0000\n",
      "cat__GEMSFoodName_FRUITING VEGETABLES: 0.0000\n",
      "cat__GEMSFoodName_Fungi, edible (not including mushrooms): 0.0000\n",
      "cat__GEMSFoodName_Goat meat: 0.0000\n",
      "cat__GEMSFoodName_Guava: 0.0000\n",
      "cat__GEMSFoodName_Jackfruit: 0.0000\n",
      "cat__GEMSFoodName_Jujube, Indian: 0.0000\n",
      "cat__GEMSFoodName_Kale: 0.0000\n",
      "cat__GEMSFoodName_Kohlrabi: 0.0000\n",
      "cat__GEMSFoodName_Kumquats: 0.0000\n",
      "cat__GEMSFoodName_LEGUME VEGETABLE: 0.0000\n",
      "cat__GEMSFoodName_Lemon: 0.0000\n",
      "cat__GEMSFoodName_Lentil (dry): 0.0000\n",
      "cat__GEMSFoodName_Lettuce, head: 0.0000\n",
      "cat__GEMSFoodName_Lime: 0.0000\n",
      "cat__GEMSFoodName_Litchi: 0.0000\n",
      "cat__GEMSFoodName_Lobsters: 0.0000\n",
      "cat__GEMSFoodName_Longan: 0.0000\n",
      "cat__GEMSFoodName_Loofah, angled (= angled gourd): 0.0000\n",
      "cat__GEMSFoodName_Loquat: 0.0000\n",
      "cat__GEMSFoodName_Mandarin + mandarin-like hybrid: 0.0000\n",
      "cat__GEMSFoodName_Mango: 0.0000\n",
      "cat__GEMSFoodName_Melons, except watermelon: 0.0000\n",
      "cat__GEMSFoodName_Milk and dairy products NES: 0.0000\n",
      "cat__GEMSFoodName_Milk fats: 0.0000\n",
      "cat__GEMSFoodName_Molluscs, including cephalopods: 0.0000\n",
      "cat__GEMSFoodName_Mulberries: 0.0000\n",
      "cat__GEMSFoodName_Mustard greens: 0.0000\n",
      "cat__GEMSFoodName_Nectarine: 0.0000\n",
      "cat__GEMSFoodName_Okra: 0.0000\n",
      "cat__GEMSFoodName_Onion, Welsh: 0.0000\n",
      "cat__GEMSFoodName_Onion, bulb: 0.0000\n",
      "cat__GEMSFoodName_Orange, sweet, sour + orange-like hybrid: 0.0000\n",
      "cat__GEMSFoodName_POME FRUITS: 0.0000\n",
      "cat__GEMSFoodName_POULTRY MEAT: 0.0000\n",
      "cat__GEMSFoodName_PULSES: 0.0000\n",
      "cat__GEMSFoodName_Papaya: 0.0000\n",
      "cat__GEMSFoodName_Peas (dry) : 0.0000\n",
      "cat__GEMSFoodName_Peas (green pods & immature seeds): 0.0000\n",
      "cat__GEMSFoodName_Peas, shelled (immature seeds): 0.0000\n",
      "cat__GEMSFoodName_Perch: 0.0000\n",
      "cat__GEMSFoodName_Persimmon, Japanese: 0.0000\n",
      "cat__GEMSFoodName_Pig, edible offal of: 0.0000\n",
      "cat__GEMSFoodName_Pineapple: 0.0000\n",
      "cat__GEMSFoodName_Plaice: 0.0000\n",
      "cat__GEMSFoodName_Plum (incl dried): 0.0000\n",
      "cat__GEMSFoodName_Pomegranate: 0.0000\n",
      "cat__GEMSFoodName_Quail eggs: 0.0000\n",
      "cat__GEMSFoodName_Quince: 0.0000\n",
      "cat__GEMSFoodName_Radish: 0.0000\n",
      "cat__GEMSFoodName_Radish, Japanese: 0.0000\n",
      "cat__GEMSFoodName_Rambutan: 0.0000\n",
      "cat__GEMSFoodName_Raspberries, red, black: 0.0000\n",
      "cat__GEMSFoodName_Rhubarb: 0.0000\n",
      "cat__GEMSFoodName_Rucola: 0.0000\n",
      "cat__GEMSFoodName_STALK AND STEM VEGETABLES: 0.0000\n",
      "cat__GEMSFoodName_STONE FRUITS: 0.0000\n",
      "cat__GEMSFoodName_Sardines and sardine-type fishes: 0.0000\n",
      "cat__GEMSFoodName_Scallops: 0.0000\n",
      "cat__GEMSFoodName_Shaddock or pomelo + shaddock-like hybrid: 0.0000\n",
      "cat__GEMSFoodName_Shallot: 0.0000\n",
      "cat__GEMSFoodName_Sharks: 0.0000\n",
      "cat__GEMSFoodName_Sheep meat: 0.0000\n",
      "cat__GEMSFoodName_Sole: 0.0000\n",
      "cat__GEMSFoodName_Soya bean (immature seeds): 0.0000\n",
      "cat__GEMSFoodName_Squash, summer (= courgette): 0.0000\n",
      "cat__GEMSFoodName_Squids: 0.0000\n",
      "cat__GEMSFoodName_Strawberry: 0.0000\n",
      "cat__GEMSFoodName_Sweet corn (corn-on-the-cob): 0.0000\n",
      "cat__GEMSFoodName_Sweet corn (kernels): 0.0000\n",
      "cat__GEMSFoodName_Tamarind (sweet): 0.0000\n",
      "cat__GEMSFoodName_Tomato paste: 0.0000\n",
      "cat__GEMSFoodName_Tree tomato: 0.0000\n",
      "cat__GEMSFoodName_Tuna: 0.0000\n",
      "cat__GEMSFoodName_Turkey meat: 0.0000\n",
      "cat__GEMSFoodName_Turnip, garden: 0.0000\n",
      "cat__GEMSFoodName_Watercress: 0.0000\n",
      "cat__GEMSFoodName_Watermelon: 0.0000\n",
      "cat__GEMSFoodName_parsley, turnip-rooted: 0.0000\n",
      "cat__ContaminantName_3-Chloro-1,2-propanediol: 0.0000\n",
      "cat__ContaminantName_Aflatoxin (total): 0.0000\n",
      "cat__ContaminantName_Aflatoxin B1: 0.0000\n",
      "cat__ContaminantName_Aflatoxin B2: 0.0000\n",
      "cat__ContaminantName_Aflatoxin G1: 0.0000\n",
      "cat__ContaminantName_Aflatoxin G2: 0.0000\n",
      "cat__ContaminantName_Aflatoxin M1: 0.0000\n",
      "cat__ContaminantName_Arsenic (inorganic): 0.0000\n",
      "cat__ContaminantName_Arsenic (total): 0.0000\n",
      "cat__ContaminantName_Cesium 134: 0.0000\n",
      "cat__ContaminantName_Cesium 137: 0.0000\n",
      "cat__ContaminantName_Cesium total: 0.0000\n",
      "cat__ContaminantName_Copper: 0.0000\n",
      "cat__ContaminantName_Deoxynivalenol: 0.0000\n",
      "cat__ContaminantName_Dioxin like PCBs (WHO TEFs): 0.0000\n",
      "cat__ContaminantName_Dioxins (WHO TEFs): 0.0000\n",
      "cat__ContaminantName_Ethyl carbamate: 0.0000\n",
      "cat__ContaminantName_Fumonisin B1: 0.0000\n",
      "cat__ContaminantName_Fumonisin B2: 0.0000\n",
      "cat__ContaminantName_Fumonisin B3: 0.0000\n",
      "cat__ContaminantName_Hexachlorobenzene: 0.0000\n",
      "cat__ContaminantName_Hexachlorocyclohexanes (HCH): 0.0000\n",
      "cat__ContaminantName_Mercury: 0.0000\n",
      "cat__ContaminantName_Methyl mercury: 0.0000\n",
      "cat__ContaminantName_Nitrite: 0.0000\n",
      "cat__ContaminantName_Ochratoxin A: 0.0000\n",
      "cat__ContaminantName_Patulin: 0.0000\n",
      "cat__ContaminantName_Pyrrolizidine alkaloids: 0.0000\n",
      "cat__ContaminantName_Tin: 0.0000\n"
     ]
    }
   ],
   "source": [
    "feature_importances = best_decision_tree_model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Get the feature names (after one-hot encoding)\n",
    "feature_names = best_decision_tree_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Create a dictionary to map feature names to their importance\n",
    "importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort the features by importance (descending)\n",
    "sorted_importances = sorted(importance_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model is working well, a random forest regressor may work better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply log transformation to the target variable (y_train and y_test)\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "# Identify categorical and numerical columns (assuming you've done this)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Create preprocessor (assuming you've done this)\n",
    "numerical_transformer = 'passthrough'\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_cols),\n",
    "                                               ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Create the Random Forest Regressor pipeline\n",
    "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', RandomForestRegressor(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid to search for Random Forest\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 3, 5],\n",
    "    'regressor__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object for Random Forest\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data (using the log-transformed target)\n",
    "grid_search_rf.fit(X_train, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters found for Random Forest\n",
    "print(f\"Best hyperparameters for Random Forest: {grid_search_rf.best_params_}\")\n",
    "\n",
    "# Get the best Random Forest model from GridSearchCV\n",
    "best_random_forest_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the best Random Forest model\n",
    "y_pred_log_rf_tuned = best_random_forest_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions back to the original scale\n",
    "y_pred_original_scale_rf_tuned = np.expm1(y_pred_log_rf_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best Random Forest model on the original scale predictions\n",
    "mse_rf_tuned = mean_squared_error(y_test, y_pred_original_scale_rf_tuned)\n",
    "r2_rf_tuned = r2_score(y_test, y_pred_original_scale_rf_tuned)\n",
    "\n",
    "print(\"\\nResults with Tuned Random Forest (Log Transformed Target):\")\n",
    "print(f'Random Forest MSE (Original Scale): {mse_rf_tuned}')\n",
    "print(f'Random Forest R-squared (Original Scale): {r2_rf_tuned}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
