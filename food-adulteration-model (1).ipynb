{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'cleaned_encode_food_adulteration.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the dates column\n",
    "df = df.drop(columns=['detection_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     brand  category  product_name  adulterant  \\\n",
      "brand             1.000000 -0.059554      0.028361   -0.034726   \n",
      "category         -0.059554  1.000000     -0.060926    0.083208   \n",
      "product_name      0.028361 -0.060926      1.000000   -0.056560   \n",
      "adulterant       -0.034726  0.083208     -0.056560    1.000000   \n",
      "detection_method  0.074250 -0.016434      0.106940    0.054394   \n",
      "health_risk       0.006836 -0.024052     -0.015533   -0.035851   \n",
      "\n",
      "                  detection_method  health_risk  \n",
      "brand                     0.074250     0.006836  \n",
      "category                 -0.016434    -0.024052  \n",
      "product_name              0.106940    -0.015533  \n",
      "adulterant                0.054394    -0.035851  \n",
      "detection_method          1.000000    -0.003260  \n",
      "health_risk              -0.003260     1.000000  \n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df[['brand', 'category', 'product_name', 'adulterant', 'detection_method', 'health_risk']], drop_first=True)\n",
    "\n",
    "# Compute Pearson correlation\n",
    "correlation_matrix = df_encoded.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severity            1.000000\n",
      "Unnamed: 0          0.081316\n",
      "adulteration_id     0.081316\n",
      "brand               0.028481\n",
      "action_taken        0.028245\n",
      "detection_method    0.019787\n",
      "health_risk         0.013633\n",
      "product_name        0.008972\n",
      "adulterant         -0.005722\n",
      "category           -0.035889\n",
      "Name: severity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display correlation of all features with 'severity'\n",
    "print(correlation_matrix['severity'].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "adulteration_id     0\n",
      "product_name        0\n",
      "brand               0\n",
      "category            0\n",
      "adulterant          0\n",
      "detection_method    0\n",
      "severity            0\n",
      "health_risk         0\n",
      "action_taken        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['product_name','adulterant']]  # Independent variables\n",
    "y = df['severity']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': None, 'bootstrap': True}\n",
      "Accuracy Score: 0.45569620253164556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.44      0.50        36\n",
      "           2       0.32      0.50      0.39        20\n",
      "           3       0.50      0.43      0.47        23\n",
      "\n",
      "    accuracy                           0.46        79\n",
      "   macro avg       0.46      0.46      0.45        79\n",
      "weighted avg       0.49      0.46      0.46        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "   'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42, class_weight=\"balanced\"),  # Added class_weight\n",
    "    param_distributions=param_dist, \n",
    "    n_iter=50,  # Increased iterations\n",
    "    cv=5, \n",
    "    scoring=\"accuracy\", \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adulteration-prediction-model.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_model, \"adulteration-prediction-model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
